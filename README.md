# üß† KEN: Cognitive Edge Network
**The Air-Gapped, Autonomous AI Co-Founder for Enterprise Developers.**

![Python](https://img.shields.io/badge/Python-3.12-blue)
![Ollama](https://img.shields.io/badge/Local_LLM-Ollama-black)
![ChromaDB](https://img.shields.io/badge/Vector_DB-Chroma-orange)
![Aider](https://img.shields.io/badge/Autonomous-Aider-red)
![License](https://img.shields.io/badge/License-MIT-green)

---

## üõë The Enterprise AI Dilemma
Corporate software developers cannot use cloud-based AI coding agents without risking massive Intellectual Property (IP) leaks. Sending proprietary codebase logic to external servers is a critical security violation. Furthermore, current cloud agents suffer from "Context Amnesia," losing the thread of complex, multi-file architectures the moment a chat session ends.

## üí° The Solution: Total Sovereignty
**KEN** is a terminal-native, fully autonomous AI engineering assistant that lives entirely on your local silicon. 

Engineered for absolute data sovereignty, KEN requires **zero cloud API calls**, incurs **zero subscription costs**, and operates with **zero internet connection**. It utilizes local hardware acceleration (CPU/GPU/NPU) to transcribe voice commands, map repository structures via GraphRAG, and execute abstract syntax tree (AST) mutations autonomously.

---

## üèóÔ∏è System Architecture

KEN operates on a dual-system cognitive loop inspired by human neurobiology:

* **üëÇ The Ears (Voice Engine):** Utilizes `Faster-Whisper` running locally on the GPU for instant, offline voice-to-text transcription with interruptible threading.
* **üï∏Ô∏è The Memory (GraphRAG):** Replaces standard vector search with a ChromaDB-powered Graph Neural Network. KEN maps project dependencies, imports, and file relationships to maintain persistent context across sessions.
* **ü¶é System 1: The Reptile Brain:** A fast, quantized local inference engine (via Ollama `qwen2.5` or `llama3.1`). It handles intent classification, telemetry routing, and instant codebase Q&A using the GraphRAG context.
* **üß† System 2: The Cortex Manager:** When mutative action is required (writing code, fixing bugs), the Reptile Brain yields execution to the Cortex. This layer spins up a local `aider-chat` worker loop to autonomously edit files, resolve syntax errors, and update the memory graph.

---

## üöÄ Getting Started

### 1. System Requirements
* **OS:** Windows / Linux / macOS
* **Hardware:** Minimum 8GB VRAM (GPU) or modern NPU/CPU for localized LLM inference.
* **Dependencies:** Python 3.10+, Node.js (for IPC bridging).

### 2. Installation
Clone the repository and install the strict environment requirements:
```bash
git clone [https://github.com/yourusername/ken-project.git](https://github.com/yourusername/ken-project.git)
cd ken-project
pip install -r requirements.txt


Gemini said
A world-class architecture deserves a world-class README.md.

When judges or recruiters land on your GitHub repository, they spend an average of 7 seconds deciding if the project is worth their time. If they see a blank page or a default template, they close the tab. If they see a structured, enterprise-grade documentation page, they immediately treat you like a Senior Engineer.

Here is the exact, professional Markdown code for your repository. It highlights your hardware-accelerated local pipeline, frames the privacy angle perfectly, and includes the "Trojan Horse" disclaimer for hackathon compliance.

Copy this entire block and paste it into your README.md file:

Markdown
# üß† KEN: Cognitive Edge Network
**The Air-Gapped, Autonomous AI Co-Founder for Enterprise Developers.**

![Python](https://img.shields.io/badge/Python-3.12-blue)
![Ollama](https://img.shields.io/badge/Local_LLM-Ollama-black)
![ChromaDB](https://img.shields.io/badge/Vector_DB-Chroma-orange)
![Aider](https://img.shields.io/badge/Autonomous-Aider-red)
![License](https://img.shields.io/badge/License-MIT-green)

---

## üõë The Enterprise AI Dilemma
Corporate software developers cannot use cloud-based AI coding agents without risking massive Intellectual Property (IP) leaks. Sending proprietary codebase logic to external servers is a critical security violation. Furthermore, current cloud agents suffer from "Context Amnesia," losing the thread of complex, multi-file architectures the moment a chat session ends.

## üí° The Solution: Total Sovereignty
**KEN** is a terminal-native, fully autonomous AI engineering assistant that lives entirely on your local silicon. 

Engineered for absolute data sovereignty, KEN requires **zero cloud API calls**, incurs **zero subscription costs**, and operates with **zero internet connection**. It utilizes local hardware acceleration (CPU/GPU/NPU) to transcribe voice commands, map repository structures via GraphRAG, and execute abstract syntax tree (AST) mutations autonomously.

---

## üèóÔ∏è System Architecture

KEN operates on a dual-system cognitive loop inspired by human neurobiology:

* **üëÇ The Ears (Voice Engine):** Utilizes `Faster-Whisper` running locally on the GPU for instant, offline voice-to-text transcription with interruptible threading.
* **üï∏Ô∏è The Memory (GraphRAG):** Replaces standard vector search with a ChromaDB-powered Graph Neural Network. KEN maps project dependencies, imports, and file relationships to maintain persistent context across sessions.
* **ü¶é System 1: The Reptile Brain:** A fast, quantized local inference engine (via Ollama `qwen2.5` or `llama3.1`). It handles intent classification, telemetry routing, and instant codebase Q&A using the GraphRAG context.
* **üß† System 2: The Cortex Manager:** When mutative action is required (writing code, fixing bugs), the Reptile Brain yields execution to the Cortex. This layer spins up a local `aider-chat` worker loop to autonomously edit files, resolve syntax errors, and update the memory graph.

---

## üöÄ Getting Started

### 1. System Requirements
* **OS:** Windows / Linux / macOS
* **Hardware:** Minimum 8GB VRAM (GPU) or modern NPU/CPU for localized LLM inference.
* **Dependencies:** Python 3.10+, Node.js (for IPC bridging).

### 2. Installation
Clone the repository and install the strict environment requirements:
```bash
git clone [https://github.com/yourusername/ken-project.git](https://github.com/yourusername/ken-project.git)
cd ken-project
pip install -r requirements.txt
3. Booting the Local Inference Engine
KEN requires a local LLM to function offline. Install Ollama and start the background server:

Bash
ollama serve
ollama pull qwen2.5:7b  # Or your preferred local model
4. Initialization
Launch the Hive Mind:

Bash
python main.py
üéôÔ∏è Command Interface
KEN is completely voice-operated. Once the terminal indicates Ears: Online, you can interact naturally:

System 1 (Context Query): "Ken, summarize the core responsibilities of the Cortex manager."

System 1 (State Check): "Ken, what file did I just ask you about?"

System 2 (Autonomous Execution): "Ken, I need you to implement a fast-doubling Fibonacci sequence in config.py."

üèÜ Hackathon Prototype Note
This architecture was engineered for the Vibe With Singularity and AMD RYZEN Slingshot hackathons.

To achieve true enterprise-grade GraphRAG memory and local voice execution natively in the terminal, we architected a custom Python/Ollama pipeline. While early web-prototyping utilized standard cloud APIs and sponsor SDKs, the final submission prioritizes absolute local execution to strictly align with the themes of Cybersecurity, Enterprise Privacy, and Edge Compute.

